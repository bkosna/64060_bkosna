---
title: "FML assignment 5"
author: "Bhuvaneshwar reddy kosna"
date: "2023-12-04"
output:
  html_document: default
  pdf_document: default
---

```{r}
# Load suitable libraries
library(cluster)
library(caret)
library(dendextend)
```

```{r}
# Load suitable libraries
library(knitr)
library(factoextra)
```

```{r}
#Importing the cereals csv file
cereals_file <- read.csv("C:/users/bhuva/Downloads/Cereals.csv")

# draw columns 4 to 16 from the 'Cereals_files' dataset and keep them in a new data frame 'cereals_file'
cereals_file <- data.frame(cereals_file[, 4:16])

```

```{r}
#Removing the missing values from the data
cereals_file <- na.omit(cereals_file)
##Data normalization and data scaling
cereals_normalization <- scale(cereals_file)
```

```{r}
#Normalizing measurements using euclidean distance and hierarchical clustering applied to the data
Euclidean <- dist(cereals_normalization, method = "euclidean")
hierarchical.clustering_complete <- hclust(Euclidean, method = "complete")

#plotting the dendogram
plot(hierarchical.clustering_complete, cex = 0.7, hang = -1)
```

```{r}
##Clustering using single, full, average, and ward links is done using the agnes() function.


hierarchical.clustering_single <- agnes(cereals_normalization, method = "single")
hierarchical.clustering_complete <- agnes(cereals_normalization, method = "complete")
hierarchical.clustering_average <- agnes(cereals_normalization, method = "average")
hierarchical.clustering_ward <- agnes(cereals_normalization, method = "ward")
```

```{r}
# outputting the hierarchical clustering_single linkage's 'ac' attribute value

print(hierarchical.clustering_single$ac)
```

```{r}
# outputting the hierarchical clustering_complete linkage's 'ac' attribute value

print(hierarchical.clustering_complete$ac)
```
```{r}
# printing 'ac' attribute value of the hierarchical clustering_average linkage
print(hierarchical.clustering_average$ac)
```
```{r}
# outputting the hierarchical clustering_ward linkage's 'ac' attribute value

print(hierarchical.clustering_ward$ac)
```

```{r}
#Using the Ward approach, plotting the dendrogram using the pltree function from the hierarchical clustering result

pltree(hierarchical.clustering_ward, cex = 0.7, hang = -1, main = "Dendrogram of agnes (Using Ward linkage)")

# Drawing rectangles around clusters to highlight them (in this example, k = 5 clusters)

rect.hclust(hierarchical.clustering_ward, k = 5, border = 1:4)
```
```{r}
# Using the cutree function based on Ward's hierarchical clustering with k=5 groupings, assign cluster labels to each observation

Cluster1 <- cutree(hierarchical.clustering_ward, k=5)

# merging the cluster labels with the original data (cereals_normalization) to create a new dataframe (dataframe2).

dataframe2 <- as.data.frame(cbind(cereals_normalization,Cluster1))
```

```{r}
#After determining the distance, we will select 5 clusters. #Building Partitions

set.seed(123)
# Creating Partition1 by selecting rows 1 to 50 from the Data_cereals dataset
Partition1 <- cereals_file[1:50,]
# Creating Partition2 by selecting rows 51 to 74 from the Data_cereals dataset
Partition2 <- cereals_file[51:74,]
```

```{r}
#Performing hierarchical Clustering,consedering k = 5 for the given linkages single, complete, average and ward respectively.
AG_single <- agnes(scale(Partition1), method = "single")
AG_complete <- agnes(scale(Partition1), method = "complete")
AG_average <- agnes(scale(Partition1), method = "average")
AG_ward <- agnes(scale(Partition1), method = "ward")

# Combining the 'ac' attribute results from different hierarchical clustering methods (single, complete, average, ward linkages respectively)
cbind(single=AG_single$ac , complete=AG_complete$ac , average= AG_average$ac , ward= AG_ward$ac)
```
```{r}
# Plotting the dendrogram using pltree function for hierarchical clustering result (AG_ward) with specified parameters
pltree(AG_ward, cex = 0.6, hang = -1, main = "Dendogram of Agnes") 

# Highlighting clusters by drawing rectangles around clusters (in this case, k = 5 clusters) based on AG_ward result
rect.hclust(AG_ward, k = 5, border = 1:4)
```

```{r}
# Assigning cluster labels to observations based on AGNES hierarchical clustering with k=5 clusters
cut_2 <- cutree(AG_ward, k = 5)
```

```{r}
#Calculating the centeroids
# Combining Partition1 and cut_2 into a new dataframe named 'result'
result <- as.data.frame(cbind(Partition1, cut_2))

# Filtering rows in 'result' where the 'cut_2' column value equals 1
result[result$cut_2==1,]
```

```{r}
# Calculating the centroid (mean) for the columns of 'result' dataframe where 'cut_2' column value is equal to 1
centroid_1 <- colMeans(result[result$cut_2==1,])

# Displaying rows in 'result' dataframe where the 'cut_2' column value is equal to 2
result[result$cut_2==2,]
```

```{r}
# Calculating the centroid (mean) for the columns of 'result' dataframe where 'cut_2' column value is equal to 2
centroid_2 <- colMeans(result[result$cut_2==2,])
# Displaying rows in 'result' dataframe where the 'cut_2' column value is equal to 3
result[result$cut_2==3,]
```

```{r}
# Calculating the centroid (mean) for the columns of 'result' dataframe where 'cut_2' column value is equal to 3
centroid_3 <- colMeans(result[result$cut_2==3,])
# Displaying rows in 'result' dataframe where the 'cut_2' column value is equal to 4
result[result$cut_2==4,]
```

```{r}
# Calculating the centroid (mean) for the columns of 'result' dataframe where 'cut_2' column value is equal to 4
centroid_4 <- colMeans(result[result$cut_2==4,])
# Combining centroids for different clusters into a matrix and then binding them row-wise
centroids <- rbind(centroid_1, centroid_2, centroid_3, centroid_4)
# Creating a new dataframe 'x2' by combining centroids' data (excluding the 14th column) with 'Partition2'
x2 <- as.data.frame(rbind(centroids[,-14], Partition2))
```

```{r}
#Calculating the Distance
# Calculating distances between points in 'x2' using the get_dist function
Distance_1 <- dist(x2)
# Converting the distance object 'Distance_1' into a matrix
Matrix_1 <- as.matrix(Distance_1)
# Creating a dataframe 'dataframe1' to store data and cluster assignments
dataframe1 <- data.frame(data=seq(1,nrow(Partition2),1), Clusters = rep(0,nrow(Partition2)))
# Looping through each row of Partition2 to assign clusters based on minimum distances
for(i in 1:nrow(Partition2))
{dataframe1[i,2] <- which.min(Matrix_1[i+4, 1:4])}
# Displaying the resulting dataframe1 containing data indices and assigned clusters
dataframe1
```

```{r}
# Combining Cluster1 values from dataframe2 for rows 51 to 74 with Clusters values from dataframe1
cbind(dataframe2$Cluster1[51:74], dataframe1$Clusters)
```

```{r}
# Creating a table to compare equality between Cluster1 values from dataframe2 (rows 51 to 74) and Clusters values from dataframe1
table(dataframe2$Cluster1[51:74] == dataframe1$Clusters)
```


# The model appears to be partially stable, as evidenced by the 12 TRUE and 12 FALSE results.

# The elementary public schools would like to choose a set of cereals to include in their daily cafeterias. Every day a different cereal is offered, but all cereals should support a healthy diet. For this goal, you are requested to find a cluster of “healthy cereals.” Should the data be normalized? If not, how should they be used in the cluster analysis

```{r}
# Creating a copy of the 'Cereals_file' dataframe named 'Healthy_Cereals'
Healthy_Cereals <- "cereals_file"
# Creating a new dataframe 'Healthy_Cereals_new' by removing rows with missing values from 'Healthy_Cereals'
Healthy_Cereals_new <- na.omit(Healthy_Cereals)
# Combining 'Healthy_Cereals_new' dataframe with 'Cluster1' obtained from previous operations into 'HealthyClust'
HealthyClust <- cbind(Healthy_Cereals_new, Cluster1)
```

```{r}
# Combining 'Healthy_Cereals_new' dataframe with 'Cluster1' obtained from previous operations into 'HealthyCluster'
HealthyClustering <- cbind(Healthy_Cereals_new, Cluster1)
```

```{r}
# Creating a copy of the 'Cereals_Data' dataframe named 'Healthy_Cereals'
Healthy_Cereals <- cereals_file
# Creating a new dataframe 'Healthy_Cereals_new' by removing rows with missing values from 'Healthy_Cereals'
Healthy_Cereals_new <- na.omit(Healthy_Cereals)
# Combining 'Healthy_Cereals_new' dataframe with 'Cluster1' obtained from previous operations into 'HealthyClust'
HealthyClust <- cbind(Healthy_Cereals_new, Cluster1)


```


```{r}
# Displaying rows in 'HealthyClust' dataframe where the 'Cluster1' column value is equal to 1
HealthyClust[HealthyClust$Cluster1==1,]

```

```{r}
# Displaying rows in 'HealthyClust' dataframe where the 'Cluster1' column value is equal to 2
HealthyClust[HealthyClust$Cluster1==2,]
```

```{r}
# Displaying rows in 'HealthyClust' dataframe where the 'Cluster1' column value is equal to 3
HealthyClust[HealthyClust$Cluster1==3,]
```

```{r}
# displaying rows from the 'HealthyClust' dataframe where the 'Cluster1' column value is equal to 4
HealthyClust[HealthyClust$Cluster1==4,]
```

```{r}
#Mean ratings to determine the best cluster.
# Calculating the mean of 'rating' values for rows in 'HealthyClust' dataframe where 'Cluster1' column value is equal to 1
mean(HealthyClust[HealthyClust$Clust1==1,"rating"])
```

```{r}
# Calculating the mean of 'rating' values for rows in 'HealthyClust' dataframe where 'Cluster1' column value is equal to 2
mean(HealthyClust[HealthyClust$Cluster1==2,"rating"])
```

```{r}
# Calculating the mean of 'rating' values for rows in 'HealthyCluster' dataframe where 'Cluster1' column value is equal to 3
mean(HealthyClust[HealthyClust$Cluster1==3,"rating"])
```

```{r}
# Finding the average of the 'rating' values for the rows in the 'HealthyCluster' dataframe where the value of the 'Cluster1' column is 4.

mean(HealthyClust[HealthyClust$Cluster1==4,"rating"])
```

Since cluster 1 has the highest mean ratings (73.84446), we can consider it.
